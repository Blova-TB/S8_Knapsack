{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eee2ecb",
   "metadata": {},
   "source": [
    "## Rapport pour agr√©ger les r√©sultats des m√©thodes TABU\n",
    "\n",
    "note : Nous avons tent√© d'int√©grer l'aspiration √† nos m√©thodes (ignorer la liste tabu si l'op√©ration donne un voisin plus grand que la meilleure solution jamais trouv√©e, mais ce n'√©tait pas probant, et plus long, donc on a rien sauvegard√© et tout laiss√© ailleurs)\n",
    "\n",
    "### Diff√©rences Algorithmiques\n",
    "\n",
    "- Tabu 1 est en gros le tabu du cours, sauf qu'il a un param√®tre pour lui laisser d√©passer la capacit√© du sac √† dos dans ses recherches. Il peut accepter des valeurs 10% plus grandes que la taille du sac, etc.\n",
    "- tabu 2 compte le poids au dessus de la capacit√© du sac a dos, le multiplie par un facteur et le soustrait √† la valeur de la somme des fitnesss des items du sac. Le facteur est param√©trable\n",
    "\n",
    "De mani√®re g√©n√©rale, il semble que tabu 2 soit plus efficace pour trouver des solutions optimale, surtout sur les pi-13...\n",
    "\n",
    "#### LES TABLEAUX SONT NOS AMIS\n",
    "\n",
    "Les 3 classes TABU_NUMPY, TABU_openCL et tabu_opencl2 donnent les m√™mes r√©sultats avec les m√™mes donn√©es de d√©part.\n",
    "\n",
    "Ils sont tous bas√© sur TABU2 (sans h√©ritage car le ctrl-c ctrl-v existe), et sont sens√©s donner des r√©sultats quasi-identiques √† celui ci (cf [ce fichier](tabu_comp_np_ocl_class.py))\n",
    "\n",
    "Ils fonctionnent en calculant avect quelques op√©rations sur des tableaux les diff√©rences de fitness des N voisins possibles.\n",
    "\n",
    "Ensuite, on r√©cup√®re l'indice de la meilleure valeur pour avoir le meilleur voisin (en prenant en compte la liste tabu )\n",
    "\n",
    "- tabu numpy le fait avec numpy\n",
    "- tabu opencl calcul les voisins sur la carte graphique avec pyopencl, puis calcul le meilleur avec numpy\n",
    "- tabu opencl2 fait tout sur la carte graphique avec des supers algos de r√©ductions\n",
    "\n",
    "Au final, numpy est le plus efficace : environ 80 fois plus rapide que le tabu 2 classique.\n",
    "\n",
    "OpenCL2 quand √† lui est environ 2 fois plus long que numpy (et encore ce n'est en prenant en compte que la r√©solution d'un probl√®me, pas la compilation du programme etc...).\n",
    "\n",
    "Dans un pc avec un CPU faible ou tr√®s occup√©, opencl pourrait √™tre plus rapide. Il pourrait √©galement l'√™tre si on utilise la classe Testor et qu'on teste autant de solutions  en parall√®le que le CPU n'a de coeurs : alors numpy ne pourrait pas aussi bien profiter du multi-processing, et utiliser la carte graphique pourrait √™tre plus int√©ressant. Enfin pour l'instant avec toutes les compilations qui se feraient √† la chaine, pas sur... (Je tente de trouver des justifications √† ces heures de d√©veloppement dans le cadre de ce projet üëÄ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe384310",
   "metadata": {},
   "source": [
    "### M√©thodo\n",
    "\n",
    "D√©j√†s on a mis en place un syst√®me de seed (apr√®s un certain temps) pour que les tests soient reproductibles (toujours sur 1 pour les tabou, la seed par d√©faut).... Il n'a pas √©t√© utilis√© sur tabu 1, mais l'a √©t√© sur une bonne part de tabu 2.\n",
    "\n",
    "On a fait varier les param√®tres 1 par un, avec peu d'it√©rations de tests pour avoir des id√©es globales.\n",
    "\n",
    "Ensuite en repartant des param√®tes qui marchent √† peu pr√®s bien pour tous (plus trop de traces de ces recherches), on a fait varier :\n",
    "1. taille de la liste TABU (avec trop d'it√©rations √† priori)\n",
    "2. nombre d'it√©ration\n",
    "3. facteur overflow  ou poids max\n",
    "4. taille initiale\n",
    "5. le nombre d'it√©rations √† nouveau, ou d'autres param√®tres en fonction.\n",
    "\n",
    "Vous pouvez aller voir les fichiers TABUX_100XX.ipynb pour voir la majorit√©s des tests effectu√©s pour trouver les param√®tres optimaux, et des jolis graphiques avec l'√©volution de la fitness en fonction de la valeur du param√®tre qui varie.\n",
    "\n",
    "### Classe Testor\n",
    "\n",
    "La classe testor permet de tester N changements d'un param√®tre d'un `Solver`. Ces solvers sont nos algorithmes TABU, g√©n√©tiques etc.\n",
    "\n",
    "On lui passe un solver pr√©parer, et une fonction pour le r√©initialiser, ansi qu'un it√©rateur qui permet de faire √©voluter le param√®tre et un entier, qui d√©fini combien de tests doivent √™tre effectu√©s pour chaque valeur du param√®tre. La seed donn√©e au d√©part doit √™tre augment√©e de 1 par la fonction qui donne le nouveau Solver, pour que le cas de test ne soit pas toujours identique (mais reproductible)\n",
    "\n",
    "Les diff√©rentes valeurs de param√®tres sont test√©es sur des threads ind√©pendants.\n",
    "\n",
    "Pour chaque groupe de test (chaque batch), sont calcul√©s : la m√©dianne, le 20√®me percentile, le 80√®me percentile ainsi que la moyenne.\n",
    "Ainsi on a des infos plut√¥t compl√®tes sur ce qui s'y passe, sans saturer le graphique.\n",
    "\n",
    "### rappel sur la Lecture des graphiques\n",
    "\n",
    "Au fil des fichiers TABUX_100XX.ipynb, des graphiques sont affich√©s. ceux ci prennent directement en param√®tre ce qui est renvoy√© de Testor.\n",
    "\n",
    "On y voit la moyenne avec un + rouge, la m√©dianne, le point bleu, et les percentile, les 2 traits verticaux autour de la m√©dianne.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b36b62",
   "metadata": {},
   "source": [
    "### Param√®tres Optimaux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e887d6",
   "metadata": {},
   "source": [
    "#### pour 100 item :\n",
    "les chiffres apr√®s repr√©sentent le sac √† dos associ√© au param√®tre (1 pour le 12, 2 pour 13, 3 -> 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabu 1\n",
    "param_tabu1_12_100 = {\"iter_max\": 200,\"tabu_size\": 60, \"max_weight\": 1, \"def_sol_size\":  0.01}\n",
    "param_tabu1_13_100 = {\"iter_max\": 2200,\"tabu_size\": 95,\"max_weight\": 1,\"def_sol_size\":  0.01}#pas sur de la reproductibilit√© sur d'autres sac de la m√™me forme\n",
    "param_tabu1_15_100 = {\"iter_max\": 200,\"tabu_size\": 60,\"max_weight\": 1,\"def_sol_size\":  0.01}\n",
    "#tabu 2\n",
    "param_tabu2_12_100 = {\"iter_max\": 200,\"tabu_size\": 60,\"cout_depassement\": 2.5,\"def_sol_size\": 0.001}\n",
    "param_tabu2_13_100 = {\"iter_max\": 200,\"tabu_size\": 60,\"cout_depassement\": 2.5,\"def_sol_size\": 0.001}\n",
    "param_tabu2_15_100 = {\"iter_max\": 200,\"tabu_size\": 60,\"cout_depassement\": 2.5,\"def_sol_size\": 0.001}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb41b1",
   "metadata": {},
   "source": [
    "#### Param√®tres pour 1000 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3811516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabu 1\n",
    "param_tabu1_12_1000 = {\"iter_max\": 5000, \"tabu_size\": 420, \"max_weight\": 1.0, \"def_sol_size\": 0.001}\n",
    "param_tabu1_13_1000 = {\"iter_max\": 3500, \"tabu_size\": 960, \"max_weight\": 1.0, \"def_sol_size\": 0.55}\n",
    "param_tabu1_15_1000 = {\"iter_max\": 3500, \"tabu_size\": 100, \"max_weight\": 1.0, \"def_sol_size\": 0.15}\n",
    "#tabu 2\n",
    "param_tabu2_12_1000 = {\"iter_max\": 500, \"tabu_size\": 200, \"cout_depassement\": 2.75, \"def_sol_size\": 0.01}\n",
    "param_tabu2_13_1000 = {\"iter_max\": 550, \"tabu_size\": 200, \"cout_depassement\": 2.75, \"def_sol_size\": 0.01}\n",
    "param_tabu2_15_1000 = {\"iter_max\": 400, \"tabu_size\": 105, \"cout_depassement\": 1.24, \"def_sol_size\": 1.4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac14b2",
   "metadata": {},
   "source": [
    "#### pour 10k items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e239d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabu 1\n",
    "param_tabu1_12_10000 = {\"iter_max\": 3000, \"tabu_size\": 420, \"max_weight\": 1.0, \"def_sol_size\": 0.001}\n",
    "param_tabu1_13_10000 = {\"iter_max\": 3000, \"tabu_size\": 960, \"max_weight\": 1.0, \"def_sol_size\": 1.0}\n",
    "param_tabu1_15_10000 = {\"iter_max\": 3000, \"tabu_size\": 100, \"max_weight\": 1.0, \"def_sol_size\": 1.0}\n",
    "#tabu 2\n",
    "param_tabu2_12_10000 = {\"iter_max\": 2500, \"tabu_size\": 800, \"cout_depassement\": 1.1, \"def_sol_size\": 0.3}\n",
    "param_tabu2_13_10000 = {\"iter_max\": 9000, \"tabu_size\": 1800, \"cout_depassement\": 2.35, \"def_sol_size\": 0.3}\n",
    "#param_tabu2_13_10000 = {\"iter_max\": 1000, \"tabu_size\": 800, \"cout_depassement\": 1.8, \"def_sol_size\": 0.3} # -> √ßa marche bien mais c'est pas parfait (seulement 99%)\n",
    "param_tabu2_15_10000 = {\"iter_max\": 9000, \"tabu_size\": 1000, \"cout_depassement\": 1.1, \"def_sol_size\": 0.3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2256c7",
   "metadata": {},
   "source": [
    "### Qualit√© des r√©sultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bfcd76",
   "metadata": {},
   "source": [
    "√† noter : nous avons chercher les r√©sultats optimaux pour chaque cas pr√©cis, et pas de mani√®re g√©n√©rale, ni en fonction de la composition de chaque sacs...\n",
    "\n",
    "Alors qu'on aurait pu imaginer des √©quations pour trouver le nombre d'it√©rations maximum ou le facteur du cout de d√©passement (par exemple, ratio moyen des 20% des meilleurs item + 10%, qui serait fonctionnel sur les 3 sacs √† 10k par exemple)\n",
    "\n",
    "On compare les r√©sultats √† ceux donn√©s par le `knapsack_solver` de `Ortools`, impl√©ment√©s avec cette fa√ßade : [Other_solver](tools/Other_solver.py)\n",
    "Ces r√©sultats sont sens√©s √™tre parfaits\n",
    "\n",
    "la qualit√© a √©t√© test√©e dans [cet ipynb](TABU_test_quality.ipynb)\n",
    "\n",
    "- par sac\n",
    "\n",
    "| %         | Tabu 1 | Tabu 2 | Temps 1 (s) | Temps 2 (s) | Ratio 2/1 |\n",
    "|-----------|--------|--------|------------------|------------------|-----------|\n",
    "| 12-100    | 100    | 100    | 1.403            | 2.644            | 0.53      |\n",
    "| 12-1000   | 100    | 100    | 27.512           | 0.178            | 154.93    |\n",
    "| 12-10000  | 100    | 100    | 76.037           | 0.934            | 81.38     |\n",
    "| 13-100    |   98.04  | 100   |  0.376            |   2.821           | 0.13     |\n",
    "| 13-1000   | 67.51  | 100    | 7.044            | 0.263            | 26.81     |\n",
    "| 13-10000  | 64.39  | 99.94  | 73.119           | 4.933            | 14.82     |\n",
    "| 15-100    | 99.1 | 99.41   |   1.156         |  2.725          | 0.42      |\n",
    "| 15-1000   | 97.55  | 99.21  | 26.783           | 0.142            | 189.07    |\n",
    "| 15-10000  | 97.54  | 99.19  | 76.641           | 3.517            | 21.79     |\n",
    "\n",
    "- par nb_item\n",
    "\n",
    "| %         | Tabu 1 | Tabu 2 | Temps 1 (s) | Temps 2 (s) | Ratio 2/1 |\n",
    "|-----------|--------|--------|------------------|------------------|-----------|\n",
    "| 12-100    | 100    | 100    | 1.403            | 2.644            | 0.53      |\n",
    "| 13-100    |   98.04  | 100   |  0.376            |   2.821           | 0.13     |\n",
    "| 15-100    | 99.1 | 99.41   |   1.156         |  2.725          | 0.42      |\n",
    "| 12-1000   | 100    | 100    | 27.512           | 0.178            | 154.93    |\n",
    "| 13-1000   | 67.51  | 100    | 7.044            | 0.263            | 26.81     |\n",
    "| 15-1000   | 97.55  | 99.21  | 26.783           | 0.142            | 189.07    |\n",
    "| 12-10000  | 100    | 100    | 76.037           | 0.934            | 81.38     |\n",
    "| 13-10000  | 64.39  | 99.94  | 73.119           | 4.933            | 14.82     |\n",
    "| 15-10000  | 97.54  | 99.19  | 76.641           | 3.517            | 21.79     |\n",
    "\n",
    "√† noter : les temps sont √† diviser par 200 pour les 100 items et 4 pour les 1000 items\n",
    "\n",
    "√† renoter : les pourcentages donn√©s sont la moyenne des pourcentages des r√©sultats, pas la m√©diane ou un percentile -> par exemple on peut explorer 10 fois 15-100 en paral√®le avec TABU 2, et on a toutes les chances de tomber sur un r√©sultat optimal (plus de 80% de chance √† chaque tirage), √ßa prendrait 0.14 secondes environ.\n",
    "#### constat\n",
    "\n",
    "Il semble que la m√©thode Tabu 2 soit globalement meilleure, √† la fois algorithmiquement, puisqu'elle trouve de meilleurs r√©sultats (surtout pour les tailles autour de 1000, elle le fait avec beaucoup moins d'it√©rations), et beaucoup plus vite d√®s que le nombre d'item augmente, m√™me si c'est surtout grace √† numpy, qu'on aurait aussi pu impl√©menter sur tabu classique.\n",
    "\n",
    "D'ailleurs plus la taille est grande moins bonnne sont nos solutions... et c'est \"logique\" : mais on trouve quand m√™me r√©guli√®rement les bonnes solution sur 12-1000, cf [ce fichier de test](TABU2_10000_i.ipynb) : on y voit qu'√† partir de 8500 it√©rations, on trouve le r√©sultat optimal dans grand minimum 80% des cas (car les barres bleues affich√©es sont les percentiles 20 et 80, et qu'elles se confondent avec la solution optimale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
